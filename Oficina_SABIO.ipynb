{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RkA-3VdwBEH3"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ni-cole17/Oficina-SABIO/blob/main/Oficina_SABIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importações"
      ],
      "metadata": {
        "id": "Aa8IQ7AfAZCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt8-inHMhCgC",
        "outputId": "3cdbbbe6-b31d-448f-cc26-0e0e402b65b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "v6UhhCkBg8qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcF_nFnojL7B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* os: A biblioteca os fornece funções para interagir com o sistema operacional.\n",
        "Ela é útil para realizar operações como acessar o sistema de arquivos, criar diretórios, gerenciar variáveis de ambiente, e etc.\n",
        "\n",
        "* cv2 (OpenCV): O OpenCV é uma biblioteca amplamente usada para processamento de imagens e visão computacional. Ele oferece uma variedade de funcionalidades, incluindo a leitura e escrita de imagens, detecção de objetos, rastreamento de objetos, manipulação de vídeo e etc.\n",
        "\n",
        "* shutil: A biblioteca shutil é usada para operações de alto nível relacionadas à manipulação de arquivos e diretórios. Ela permite copiar, mover, renomear e excluir arquivos e diretórios de forma eficiente.\n",
        "\n",
        "* ultralytics.YOLO: A biblioteca Ultralytics é uma API para trabalhar com detecção de objetos usando a arquitetura YOLO (You Only Look Once). Ela oferece um conjunto de ferramentas para treinar, avaliar e usar modelos YOLO para tarefas de detecção de objetos em imagens e vídeos."
      ],
      "metadata": {
        "id": "Ngs2oD4NP59C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base de dados"
      ],
      "metadata": {
        "id": "bKIW6emoAybk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando a base"
      ],
      "metadata": {
        "id": "i0yq3IJnYc_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "v37TvHbBYUbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b04a59-0240-481c-a96b-3bb92d64ccb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Oficina - SABIO/database.zip\""
      ],
      "metadata": {
        "id": "__hVyKQIA2Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificando contagem de cada classe"
      ],
      "metadata": {
        "id": "_jX8OXJ3YiaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Declaração da lista classes para armazenar as classes do nosso dataset\n",
        "classes = []\n",
        "## Iteração na base de imagens original e print da quantidade de imagens por cada classe\n",
        "for classe in os.listdir(\"Original\"):\n",
        "    classes.append(classe)\n",
        "    print(f'{classe}: {len(os.listdir(os.path.join(\"Original\",classe)))}')"
      ],
      "metadata": {
        "id": "eobxEJOBYl8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d653175c-ac26-4851-b2ba-953d8e54176d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basophil: 218\n",
            "Monocyte: 242\n",
            "Neutrophil: 242\n",
            "Lymphocyte: 242\n",
            "Eosinophil: 201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split em treino/teste/validação"
      ],
      "metadata": {
        "id": "p4MhlXuBZA5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Vamos escolher o split de (80% treino | 10% teste | 10% validação)\n",
        "\n",
        "## Escolha da contagem da classe com menos representação\n",
        "total = 201\n",
        "## Definindo o tamanho de treino, teste e validação\n",
        "train_size = int(80 * total / 100)\n",
        "val_size = int(10 * total / 100)\n",
        "test_size = total - train_size - val_size\n",
        "## Printando os valores\n",
        "print(train_size,val_size,test_size)"
      ],
      "metadata": {
        "id": "rvqDHs8ZZG0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9527dd00-2e87-45b2-e3ae-5b1b5b308fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160 20 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Criando a base de dados no formato para \"entregar\" para o modelo\n",
        "'''\n",
        "database\n",
        "|_train\n",
        "    |_classe1\n",
        "    |_classe2\n",
        "    |_classe3\n",
        "    ...\n",
        "|_test\n",
        "    |_classe1\n",
        "    |_classe2\n",
        "    |_classe3\n",
        "    ...\n",
        "|_val\n",
        "    |_classe1\n",
        "    |_classe2\n",
        "    |_classe3\n",
        "    ...\n",
        "'''\n",
        "for classe in classes:\n",
        "    os.makedirs(os.path.join(\"database\",\"train\",classe),exist_ok = True)\n",
        "    os.makedirs(os.path.join(\"database\",\"test\",classe),exist_ok = True)\n",
        "    os.makedirs(os.path.join(\"database\",\"val\",classe),exist_ok = True)"
      ],
      "metadata": {
        "id": "jlbkutxDZGrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Movendo as imagens da base original para a base de dados do modelo\n",
        "for classe in classes:\n",
        "    for img in os.listdir(os.path.join(\"Original\", classe)):\n",
        "        if len(os.listdir(os.path.join(\"database\",\"val\",classe))) < val_size:\n",
        "            shutil.copy(os.path.join(\"Original\", classe, img),os.path.join(\"database\",\"val\",classe))\n",
        "        elif len(os.listdir(os.path.join(\"database\",\"train\",classe))) < train_size:\n",
        "            shutil.copy(os.path.join(\"Original\", classe, img),os.path.join(\"database\",\"train\",classe))\n",
        "        elif len(os.listdir(os.path.join(\"database\",\"test\",classe))) < test_size:\n",
        "            shutil.copy(os.path.join(\"Original\", classe, img),os.path.join(\"database\",\"test\",classe))"
      ],
      "metadata": {
        "id": "8m1l0FXuaDdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Verificando a contagem de treino, teste e validação\n",
        "for patch in os.listdir(\"database\"):\n",
        "    print(patch)\n",
        "    for classe in os.listdir(os.path.join(\"database\",patch)):\n",
        "        print(f'{classe}: {len(os.listdir(os.path.join(\"database\",patch,classe)))}')"
      ],
      "metadata": {
        "id": "PkL-b7OQjmUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição e treino do modelo"
      ],
      "metadata": {
        "id": "D8HV5Xf5A1cJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentação: https://docs.ultralytics.com/modes/train/#usage-examples"
      ],
      "metadata": {
        "id": "O1p2HpR_mUJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n-cls.pt') ## Modelo pré treinado da Imagenet"
      ],
      "metadata": {
        "id": "XvbMHSivA6rf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac055f6-0a6d-4010-ce5b-6aa9ab21196f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n",
            "100%|██████████| 5.28M/5.28M [00:00<00:00, 114MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Verificando o tamanho das imagens\n",
        "img = cv2.imread(\"/content/Original/Eosinophil/95-5-10-1_178_2.jpg\")\n",
        "print(img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0MytH8xl_Pf",
        "outputId": "cf26743b-91ad-4676-b068-5a5b3bb7ab7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(575, 575, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Treino do modelo (Hiperparâmetros: nº de épocas, tamanho da imagem de entrada,...)\n",
        "results = model.train(data = \"database\", epochs=10, imgsz=608)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yltuWTd4l1Lp",
        "outputId": "00b3fcd4-8218-4ca7-c2c4-1324a82812aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.207 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=database, epochs=10, patience=50, batch=16, imgsz=608, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/database/train... found 800 images in 5 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/database/val... found 100 images in 5 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/database/test... found 105 images in 5 classes ✅ \n",
            "Overriding model.yaml nc=1000 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    336645  ultralytics.nn.modules.head.Classify         [256, 5]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1444693 parameters, 1444693 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 108MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/database/train... 800 images, 0 corrupt: 100%|██████████| 800/800 [00:00<00:00, 4829.12it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/database/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=608, width=608, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/database/val... 100 images, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 4025.44it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/database/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 608 train, 608 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/10      1.58G     0.4128         16        608:  16%|█▌        | 8/50 [00:03<00:12,  3.29it/s]Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "       1/10      1.58G     0.4108         16        608:  24%|██▍       | 12/50 [00:04<00:12,  2.93it/s]\n",
            "100%|██████████| 755k/755k [00:00<00:00, 17.4MB/s]\n",
            "       1/10      1.58G     0.3382         16        608: 100%|██████████| 50/50 [00:16<00:00,  3.07it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00,  5.23it/s]\n",
            "                   all       0.51          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       2/10      1.43G     0.1854         16        608: 100%|██████████| 50/50 [00:14<00:00,  3.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 18.81it/s]\n",
            "                   all       0.93          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       3/10      1.43G    0.08047         16        608: 100%|██████████| 50/50 [00:21<00:00,  2.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 20.57it/s]\n",
            "                   all       0.95          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       4/10      1.43G    0.05986         16        608: 100%|██████████| 50/50 [00:14<00:00,  3.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 17.84it/s]\n",
            "                   all       0.92          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       5/10      1.43G    0.04708         16        608: 100%|██████████| 50/50 [00:14<00:00,  3.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 18.88it/s]\n",
            "                   all       0.97          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       6/10      1.43G    0.03298         16        608: 100%|██████████| 50/50 [00:14<00:00,  3.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 19.42it/s]\n",
            "                   all       0.97          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       7/10      1.43G    0.02495         16        608: 100%|██████████| 50/50 [00:14<00:00,  3.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 18.23it/s]\n",
            "                   all       0.98          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       8/10      1.43G    0.02448         16        608: 100%|██████████| 50/50 [00:15<00:00,  3.32it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 16.99it/s]\n",
            "                   all       0.97          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       9/10      1.43G    0.02278         16        608: 100%|██████████| 50/50 [00:14<00:00,  3.47it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 19.99it/s]\n",
            "                   all       0.98          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      10/10      1.43G    0.01863         16        608: 100%|██████████| 50/50 [00:14<00:00,  3.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00, 17.81it/s]\n",
            "                   all       0.98          1\n",
            "\n",
            "10 epochs completed in 0.047 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.207 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1441285 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/database/train... found 800 images in 5 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/database/val... found 100 images in 5 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/database/test... found 105 images in 5 classes ✅ \n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 4/4 [00:00<00:00,  7.36it/s]\n",
            "                   all       0.98          1\n",
            "Speed: 1.9ms preprocess, 1.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Validando o modelo\n",
        "metrics = model.val(data = \"database\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7LpIUxPmjDk",
        "outputId": "288305f5-4323-4f8a-a6da-9948059cce11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.207 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1441285 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/database/train... found 800 images in 5 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/database/val... found 100 images in 5 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/database/test... found 105 images in 5 classes ✅ \n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/database/val... 100 images, 0 corrupt: 100%|██████████| 100/100 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:03<00:00,  1.82it/s]\n",
            "                   all       0.98          1\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métricas"
      ],
      "metadata": {
        "id": "RkA-3VdwBEH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "7dMJQuTeBG4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c343b6f6-86e0-49b2-ed01-d1b7c1b93dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ed415d568f0>\n",
              "curves: []\n",
              "curves_results: []\n",
              "fitness: 0.9899999797344208\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 0.9799999594688416, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9899999797344208}\n",
              "save_dir: PosixPath('runs/classify/train2')\n",
              "speed: {'preprocess': 1.8219923973083496, 'inference': 11.443593502044678, 'loss': 0.0017571449279785156, 'postprocess': 0.0015091896057128906}\n",
              "task: 'classify'\n",
              "top1: 0.9799999594688416\n",
              "top5: 1.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predição"
      ],
      "metadata": {
        "id": "SVD9oLPmJlAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Carregando o melhor modelo treinado\n",
        "model = YOLO('/content/runs/classify/train/weights/best.pt')"
      ],
      "metadata": {
        "id": "8aLWDYkMJm2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Inferência em uma imagem\n",
        "results = model([\"/content/database/test/Neutrophil/95-5-10-1_585_2.jpg\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0GwevYeJmlE",
        "outputId": "c98783cb-ef7e-4ab5-ebf2-9df831b5ddb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 608x608 Neutrophil 0.90, Eosinophil 0.09, Lymphocyte 0.01, Monocyte 0.00, Basophil 0.00, 5.2ms\n",
            "Speed: 12.8ms preprocess, 5.2ms inference, 0.2ms postprocess per image at shape (1, 3, 608, 608)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"runs/\" \"/content/drive/MyDrive/Oficina - SABIO\""
      ],
      "metadata": {
        "id": "FdG0SawhSCx7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}